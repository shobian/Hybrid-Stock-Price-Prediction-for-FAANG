{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shobians./Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "Pandas version: 2.2.3\n",
      "Numpy version: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "# If needed:\n",
    "# !pip install pandas numpy scikit-learn tensorflow pandas_ta --quiet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_ta as ta  # For RSI, MACD, Moving Averages\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"Numpy version:\", np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the merged CSV with Apple prices + sentiment.\n",
    "\n",
    "csv_file = \"merged_news_stock_data.csv\"  # adjust if needed\n",
    "\n",
    "df = pd.read_csv(csv_file, parse_dates=[\"Date\"])\n",
    "df.sort_values(\"Date\", inplace=True)\n",
    "df.dropna(subset=[\"Date\"], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Columns in dataset:\", df.columns.tolist())\n",
    "print(\"Row count:\", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Compute RSI, MACD, Moving Average\n",
    "\n",
    "Using **pandas_ta** to get:\n",
    "1. **RSI** (14-day)\n",
    "2. **MACD** (12,26,9) plus signal line\n",
    "3. **50-day SMA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"RSI\"] = ta.rsi(df[\"Close\"], length=14)\n",
    "\n",
    "# MACD\n",
    "macd_data = ta.macd(df[\"Close\"])  # yields MACD_12_26_9, MACDh_12_26_9, MACDs_12_26_9\n",
    "df[\"MACD\"] = macd_data[\"MACD_12_26_9\"]\n",
    "df[\"MACD_signal\"] = macd_data[\"MACDs_12_26_9\"]  # the signal line\n",
    "\n",
    "# Moving Average (50-day)\n",
    "df[\"SMA_50\"] = ta.sma(df[\"Close\"], length=50)\n",
    "\n",
    "# Drop rows that turned NaN due to rolling calculations\n",
    "df.dropna(subset=[\"RSI\", \"MACD\", \"MACD_signal\", \"SMA_50\"], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"After adding RSI, MACD, SMA_50:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"future_close\"] = df[\"Close\"].shift(-1)\n",
    "df[\"target_up\"] = (df[\"future_close\"] > df[\"Close\"]).astype(int)\n",
    "# Drop last row which has no future_close\n",
    "df.dropna(subset=[\"future_close\"], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Select Feature Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"Close\", \n",
    "    \"Volume\",\n",
    "    \"RSI\", \n",
    "    \"MACD\", \n",
    "    \"MACD_signal\", \n",
    "    \"SMA_50\",\n",
    "    \"sentiment_polarity\",\n",
    "    \"sentiment_neg\",\n",
    "    \"sentiment_neu\",\n",
    "    \"sentiment_pos\"\n",
    "]\n",
    "\n",
    "df_model = df[[\"Date\"] + feature_cols + [\"target_up\"]].copy()\n",
    "df_model.dropna(inplace=True)\n",
    "print(\"df_model columns:\", df_model.columns.tolist())\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Build Sequences for LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Scale features (so RSI, Volume, Sentiment are on similar numeric scales)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_model_scaled = df_model.copy()\n",
    "df_model_scaled[feature_cols] = scaler.fit_transform(df_model_scaled[feature_cols])\n",
    "\n",
    "# 2) Convert to sequences\n",
    "lookback = 5\n",
    "\n",
    "vals = df_model_scaled[feature_cols].values  # shape (N, num_features)\n",
    "targets = df_model_scaled[\"target_up\"].values\n",
    "\n",
    "X, y = [], []\n",
    "for i in range(len(vals) - lookback):\n",
    "    seq_x = vals[i : i+lookback]\n",
    "    label = targets[i + lookback]\n",
    "    X.append(seq_x)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"X shape:\", X.shape, \"y shape:\", y.shape)\n",
    "# e.g. X shape: (samples, 5, #features), y shape: (samples,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Train/Test Split (Time-based)\n",
    "We'll do an 80/20 split by index. The first 80% for training, last 20% for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(X))\n",
    "X_train = X[:train_size]\n",
    "y_train = y[:train_size]\n",
    "X_test = X[train_size:]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "print(\"Train size:\", X_train.shape[0], \"Test size:\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Build LSTM Model\n",
    "We'll do a single-layer LSTM with 64 units, plus a Dense(1) for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Input(shape=(lookback, len(feature_cols))))\n",
    "model.add(layers.LSTM(64, return_sequences=False))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", acc)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Next Steps\n",
    "- Adjust **lookback** if you want a longer or shorter window.\n",
    "- Tweak the LSTM layer size (64→128) or add dropout.\n",
    "- Add more features or different sentiment transforms.\n",
    "- Increase the **epochs** if underfitting, but watch for overfitting.\n",
    "- Use a more advanced train/test methodology like walk-forward validation.\n",
    "- Evaluate the model’s predictions with a trading strategy or backtest approach."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Apple_Stock_Prediction",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
